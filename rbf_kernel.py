# -*- coding: utf-8 -*-
"""RBF_Kernel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vym1vCmRmepRm0UlSY8ViTDCKYYQmdCy
"""

# Improved EDA and Data Preprocessing
# EDA and data preprocess
# https://github.com/NissyAbrahamA/Spam-Detection/blob/main/EmailSpamDetection.ipynb

!pip3 install pandas
!pip3 install numpy
!pip3 install nltk

import numpy as np
import pandas as pd
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.corpus import stopwords
from nltk import FreqDist
from nltk.tokenize import word_tokenize
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS
import string
import seaborn as sns
import plotly.graph_objects as go
from gensim.models import Word2Vec, FastText
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.pipeline import Pipeline
import re
import warnings

warnings.filterwarnings('ignore')

data=pd.read_csv('/content/spam_ham_dataset.csv')
data.head()

data.info()

data["label_num"].value_counts()

data

data=data.drop(["Unnamed: 0", "label"],axis=1)

data.head()

data['subject']=data['text'].str.extract(r'subject:(.*?)\r\n', flags=re.IGNORECASE)
data['text']=data['text'].str.replace(r'subject:.*?\r\n', '', flags=re.IGNORECASE)
data.head()

label_counts=data['label_num'].value_counts()
plt.bar(['0', '1'], label_counts.values)
plt.xlabel('Label')
plt.ylabel('Count')
plt.title('Label Counts')
plt.show()

data=data.applymap(lambda x: re.sub(r'\W+', ' ', str(x)))

stopwords = nltk.corpus.stopwords.words('english')
connecting_words = ['and', 'or', 'but', 'the', 'a','for']
data=data.applymap(lambda x: ' '.join([word for word in re.split(r'\W+', str(x)) if word.lower() not in stopwords and word.lower() not in connecting_words]))

X_train, X_temp, y_train, y_temp = train_test_split(data['text'], data['label_num'], test_size=0.5, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

svm_rbf_pipeline=Pipeline([('vect',CountVectorizer()),
                           ('tfidf', TfidfTransformer()),
                           ('svm', SVC(kernel='rbf'))])

svm_rbf_pipeline.fit(X_train, y_train)

val_predictions=svm_rbf_pipeline.predict(X_val)

val_accuracy = accuracy_score(y_val, val_predictions)
print(f'Validation Accuracy: {val_accuracy:.2f}')

test_predictions = svm_rbf_pipeline.predict(X_test)

test_accuracy = accuracy_score(y_test, test_predictions)
print(f'Test Accuracy: {test_accuracy:.2f}')

print("Classification Report on Test Data:\n", classification_report(y_test, test_predictions))

conf_matrix = confusion_matrix(y_test, test_predictions)
print("Confusion Matrix:")
print(conf_matrix)

sns.heatmap(conf_matrix, annot = True, fmt = 'd')
plt.xlabel('Predicted')
plt.ylabel('Actual')
print(classification_report(y_test , test_predictions))